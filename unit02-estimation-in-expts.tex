% TODOS:
% Add intro to IVs, in the Bloom's method sense



%  For slides only
\input{slidesonly}

% % For handout
%\input{handout}

%For handout + mynotes
%\input{handout+mynotes}

\input{beamer-preamble-bbh-all}
\input{defs-all}

\title{Unit 2: Estimation in experiments}
% \author moved to beamer-preamble-*-all.tex
\date{July 2015}

\begin{document}


  \begin{frame}
    \frametitle{Outline \& Readings}

\tableofcontents[subsectionstyle=show/hide/hide]

\input{announcement-of-the-day}  % announcement-of-the-day.tex not
                                % part of repo
\end{frame}


\begin{frame}<\nottheirhandout>{Exercise: random assignment methods}
{\footnotesize (G\&G ch1 ex 5)}

\begin{enumerate} \addtocounter{enumi}{-1}
\item
A researcher plans to ask six subjects to donate time to an adult
literacy program. Each subject will be asked to donate either 30 or 60
minutes. The researcher is considering three methods for randomizing
the treatment. One method is to flip a coin before talking to each
person and to ask for a 30-minute donation if the coin comes up heads
or a 60-minute donation if it comes up tails. The second method is to
write ``30'' and ``60'' on three playing cards each, and then shuffle
the six cards.\ldots
  
\begin{itemize}
\item[a] Discuss strengths \& weaknesses of each approach.
\item[b] How would your answers to (a) change if $n: 6 \mapsto 600$?
\item[c] Calculate $\mathbf{E}(Z_{1})$ under each of the two methods.
\end{itemize}
\end{enumerate}

\end{frame}
\note{W2016: SKIP THIS}

\section{Overview}



\begin{frame}{Unit 2, estimating causal parameters}
  \begin{itemize}
  \item In coffee/tea tasting examples, easier to think about whether causation occurred than how one might measure it.
  \item Now, examples that lend themselves to talk of ``average causal effects,'' etc.
%  \item ``effect'' will have a different and more specific meaning than elsewhere in statistics; we'll begin by talking about it.
  \item We'll continue to use methods that don't care whether outcomes
    are binary, continuous, etc, and avoid distributional assumptions.
  \item We will add an assumption of \textit{non-interference} (aka ``SUTVA'')
  \item In contrast to unit 1, focus on estimation rather than testing.
  \end{itemize}
\end{frame}

\begin{frame}{Average causal effect estimates for simple
    experiments\footnote{Example from Gerber and Green (2012) ch. 2.}}


  \begin{columns}
    \begin{Column}
        \igrphx{ggch2tab2}
    \end{Column}
    \begin{Column}
      
    \end{Column}
  \end{columns}

  
\end{frame}

\section{Potential outcome schedules}

\begin{frame}{Random variable notation; vector notation}
  
  \begin{itemize}
  \item By convention, $X, Y, Z$ denote random variables (RVs); $x, y, z$, realizations of the RVs.
    \begin{itemize}
    \item Rosenbaum (a statistician) observes this convention\ldots
    \item as I will.
    \item G\& G (political scientists) appear not to.
    \end{itemize}
  \item $Z_i$= RV for subject $i$; $\mathbf{Z}=(Z_1, Z_2, \ldots, Z_n)'$ (a column vector).  Likewise for $X$, $Y$.
  \item Also $\mathbf{z}=(z_1, z_2, \ldots, z_n)$, and similarly for $\mathbf{x}$, $\mathbf{y}$
  \end{itemize}


\end{frame}

\begin{frame}<\nottheirhandout>{Exercise: random assignment methods}
{\footnotesize (G\&G ch1 ex 5)}

\begin{enumerate}\addtocounter{enumi}{-1}
\item 
A researcher plans to ask six subjects to donate time to an adult
literacy program. Each subject will be asked to donate either 30 or 60
minutes. The researcher is considering three methods for randomizing
the treatment. One method is to flip a coin before talking to each
person and to ask for a 30-minute donation if the coin comes up heads
or a 60-minute donation if it comes up tails. The second method is to
write ``30'' and ``60'' on three playing cards each, and then shuffle
the six cards.\ldots

\begin{itemize}
\item[d] Calculate $\mathbf{E}(\mathbf{Z}'\mathbf{Z})$ under each of the two methods.
\item[e] For which of the two methods does $\mathrm{Var}((\mathbf{Z}'\mathbf{Z})) = 0$?
\end{itemize}
\end{enumerate}
\vfill

\visible<2>{Either way, cannonical analyses treat observations as
\textit{independent} samples, sizes $n_{0}$ and $n_{1}$, from
``\textit{superpopulations}'' of size $N_{0}, N_{1} \approx
\infty$.  We'll see how one such analysis flows from more serious assumptions.}
\end{frame}


\begin{frame}{$Z$s/$z$s vs $D$s/$d$s}
  
Additional conventions, this time shared by DOS, G\& G and this course:

\begin{tabular}{cc}
  $Y$ & outcome \\
  $X$ & covariate/baseline variable\\
  $Z$ & treatment assignment\\
  $D$ & treatment received \\
\end{tabular}
\pause

(Each may appear in caps or lowercase, indicating an RV or a realization; each may be bolded to indicate a vector.) \pause

In the coffee experiment, $\mathbf{D} \equiv \mathbf{Z}$; also in experiments discussed in G\& G ch.2.  In general they may diverge (non-compliance). 

\end{frame}

\begin{frame}{Potential outcome schedules}%{Two potential outcome schedule for the coffee experiment}

  A \textit{potential outcome schedule} %
%\footnote{G.\&G. ch.2; concept due to Freedman (\textit{Statistical Models\ldots}, C.U.P., 2009).}
is a mapping of assignment vectors $\mathbf{z} = (z_1, \ldots, z_n)'$,
all or mostly counter-to-fact, to outcomes.  Alternatively, a listing of
how each study participant would have responded to
any combination of assignments $\mathbf{z}$ that
the experiment could have produced. Two examples:\\
\begin{columns}
  \begin{Column}
%\hspace{1em} 
    \begin{center}
         {\usebeamercolor[fg]{titlelike} Fisher's null} 
    \end{center}
\begin{tabular}{cccc}
    \begin{tabular}{cc} \hline
 $\mathbf{z}$ & $\mathbf{y}$ \\ \hline
1 &   0 \\
1 &   0 \\
1 &   0 \\
1 &   0 \\
0 &   1 \\
0 &   1 \\
0 &   1 \\
0 &   1 \\ \hline
    \end{tabular}
&
    \begin{tabular}{cc} \hline
 $\mathbf{z}$ & $\mathbf{y}$ \\ \hline
1 &    0 \\
1 &    0 \\
1 &    0 \\
0 &    0 \\
1 &    1 \\
0 &    1 \\
0 &    1 \\
0 &    1 \\ \hline
    \end{tabular}
&
$\cdots$
&
    \begin{tabular}{cc} \hline
 $\mathbf{z}$ & $\mathbf{y}$ \\ \hline
0 &    0 \\
0 &    0 \\
0 &    0 \\
0 &    0 \\
1 &    1 \\
1 &    1 \\
1 &    1 \\
1 &    1 \\ \hline
    \end{tabular}
\end{tabular}
\end{Column}
  \begin{Column}
%\hspace{1em}  
    \begin{center}
       {\usebeamercolor[fg]{titlelike} Perfect discrimination} 
    \end{center}
\begin{tabular}{cccc}
    \begin{tabular}{cc} \hline
 $\mathbf{z}$ & $\mathbf{y}$ \\ \hline
1 & 1  \\
1 & 1  \\
1 & 1  \\
1 & 1  \\
0 & 0  \\
0 & 0  \\
0 & 0  \\
0 & 0  \\ \hline
    \end{tabular}
&
    \begin{tabular}{cc} \hline
 $\mathbf{z}$ & $\mathbf{y}$ \\ \hline
 1& 1  \\
 1& 1  \\
 1& 1  \\
 0& 0  \\
 1& 1  \\
 0& 0  \\
 0& 0  \\
 0& 0  \\ \hline
    \end{tabular}
&
$\cdots$
& 
    \begin{tabular}{cc} \hline
 $\mathbf{z}$ & $\mathbf{y}$ \\ \hline
0 & 0  \\
0 & 0  \\
0 & 0  \\
0 & 0  \\
1 & 1  \\
1 & 1  \\
1 & 1  \\
1 & 1  \\ \hline
    \end{tabular}
  \end{tabular}
\end{Column}
\end{columns}
\pause \medskip

Strict null hypotheses are potential outcome schedules, but not conversely. 

\end{frame}
\itnote{
\item Walk them through -- meanings not self-evident!
}

\begin{frame}<\nottheirhandout>{Aside: Test statistics \& response schedules}
  
\begin{itemize}
\item One \texttt{test statistic} we discussed for the coffee experiment is the number of ``fancy-coffee'' cups among the cups identified as containing fancy coffee $y=1$. This translates to $Z'Y$. \pause


\item The worksheet (\texttt{unit01-Rex}) has $Z'y$.  This leans on the fact that it assumes Fisher's null, under which $y$ is the same, whatever $Z$ may be. \pause

\item When we're entertaining the possibility of perfect discrimination, we'd have to write $Z'Y$ .
\item We also entertained the treatment-group mean of $y$s as a test
  statistic. To emphasize dependence on $Z$, write this as $Z'y/n_{t}$
  ($Z'Y/n_{t}$). Or, if size of treatment group might be a random
  variable, $Z'y/Z'Z$  ($Z'Y/Z'Z$).
\end{itemize}
\end{frame}
\note{W16: SKIP ME}
\begin{frame}{Potential outcome schedules}
  
  A \textit{potential outcome schedule}%
\footnote{G.\&G. ch.2; concept due to Freedman (\textit{Statistical Models\ldots}, C.U.P., 2009).}
is a mapping of assignment vectors $\mathbf{z} = (z_1, \ldots, z_n)'$,
all or mostly counter-to-fact, to outcomes.  Alternatively, a listing of
how each study participant would have responded to
any combination of assignments $\mathbf{z}$ that
the experiment could have produced. Two examples:\\

\begin{columns}
  \begin{Column}
\hspace{1em}    {\usebeamercolor[fg]{titlelike} Fisher's null} \\
    \begin{tabular}{ccc} \hline
 $\mathbf{z}$& $\mathbf{d} $ & $\mathbf{y}$ \\ \hline
$z_1$ &$z_1$ &  0   \\
$z_2$ &$z_2$ &  0   \\
$z_3$ &$z_3$ &  0   \\
$z_4$ &$z_4$ &  0   \\
$z_5$ &$z_5$ &  1   \\
$z_6$ &$z_6$ &  1   \\
$z_7$ &$z_7$ &  1   \\
$z_8$ &$z_8$ &  1   \\ \hline
    \end{tabular}

  \end{Column}
  \begin{Column}
\hspace{1em}   {\usebeamercolor[fg]{titlelike} Perfect discrimination} \\
    \begin{tabular}{ccc} \hline
 $\mathbf{z}$ & $\mathbf{d} $ & $\mathbf{y}$ \\ \hline
$z_1$ &$z_1$ & $z_1$  \\
$z_2$ &$z_2$ & $z_2$  \\
$z_3$ &$z_3$ & $z_3$  \\
$z_4$ &$z_4$ & $z_4$  \\
$z_5$ &$z_5$ & $z_5$  \\
$z_6$ &$z_6$ & $z_6$  \\
$z_7$ &$z_7$ & $z_7$  \\
$z_8$ &$z_8$ & $z_8$  \\ \hline
    \end{tabular}

  \end{Column}

\end{columns}

\end{frame}
\itnote{
\item Explain $z$ vs $d$. 
\item W16 SKIP ME (Sketch sampling distributions of $T = Z'y = D'y$)
}

\begin{frame}{Potential outcomes}
  
A much more common way of specifying potential outcome schedules is to
specify \textit{potential outcomes}.  For binary $Z$, and w/ perfect
compliance ($\mathbf{d} \equiv \mathbf{z}$), potential outcomes would be specified as

\begin{columns}
\begin{Column}
    \begin{tabular}{cc} \hline
 $\mathbf{y}_0$ & $\mathbf{y}_1$ \\ \hline
$y_{01}$ & $y_{11}$  \\
$y_{02}$ & $y_{12}$  \\
$y_{03}$ & $y_{13}$  \\
$\vdots$ & $\vdots$  \\
$y_{0n}$ & $y_{1n}$  \\ \hline
    \end{tabular}
\pause
\end{Column}

\begin{Column}
Notes:\\

\begin{itemize}[<+->]
\item (Post-It analogy)
\item Assumes each subject $i$'s response depends only on $d_{i}$, not
  other $d$s.
\item not appropriate for coffee experiment
\item not necessarily appropriate for Salk trial
\item \textit{non-interference} has been assumed
\item \ldots often unwittingly! 
\end{itemize}
  
\end{Column}
\end{columns}

\end{frame}

\begin{frame}<\nottheirhandout>{Exercises}
  \begin{enumerate}
  \item Re potential outcomes notation {}(G.\&G. ex.1, ch 1):
    \begin{enumerate}
    \item Explain the notation $Y_{i}(0)$ (as appears in G\&G 2012).
    \item Contrast the meaning of ``$Y(0) | Z=1$'' w/ that of ``$Y(0) | Z=0$''.
    \item How does $\mathbf{E}(Y(1) | Z=1)$ differ in meaning from $\mathbf{E}(Y(1))$?
    \item Give an example of type of study in which $\mathbf{E}(Y(1) | Z=1) = \mathbf{E}(Y(1))$, explaining why they're the same.
    \item Given an example of real or hypothetical study in which $\mathbf{E}(Y(1) | Z=1) \neq \mathbf{E}(Y(1))$.
    \item Do randomized studies always satisfy $\mathbf{E}(Y(1) | Z=1)
      = \mathbf{E}(Y(1))$?  Why or why not?
    \item Do randomized studies always satisfy $\mathbf{E}(Y(1) | D=1)
      = \mathbf{E}(Y(1))$?  (What's the difference between this q and
      the last one?)
    \end{enumerate}
\item (G.\&G. ex.4, ch 1) Suppose $z_{i} \in \{0,1\}$, all $i$; assume non-interference. Define the ATT as $\mathbf{z}'(\mathbf{y}_{T}-\mathbf{y}_{C})/\mathbf{z}'\mathbf{z}$.  Prove that if treatments are allocated using complete random assignment, then the ATT is equal in expectation to the average treatment effect.
  \end{enumerate}

\end{frame}
\note{W16: Maybe skip Q2, in interests of moving along?}
\section{Expectations and ACEs}

\begin{frame}{Probability review\footnote{See also G\& G, ch 2}}

  \begin{itemize}
  \item Fix a probability distribution for each RV.
  \item (For simplicity, assume discrete.  As $\mathbf{Z}$ is discrete, in a randomized experiment)
  \item  $\mathrm{E}(V) = \sum_v v\mathrm{P}(V=v) $, where $v$ ranges over possible values of $V$.
  \item $\mathrm{E}(V + W) = \mathrm{E}(V) + \mathrm{E}(W)$.
  \item For constant $c$, $\mathrm{E}(cV) = c\mathrm{E}(V)$.
  \item In particular, 
$$\mathrm{E}\left(\frac{1}{n} \sum_{i=1}^n V_i\right) = \frac{1}{n} \sum_{i=1}^n \mathrm{E} V_i.$$
  \end{itemize}


\end{frame}

\begin{frame}{Test statistics and estimators}
  
\end{frame}
\itnote{
\item estimator/estimand; (statistic/parameter)
\item $\mathrm{E}(Y(1))$ as a parameter
\item $\frac{1}{N}\sum y_{Ti} = \mu_{1}$ as a parameter
\item $\mathbf{Z}'\mathbf{y}/(\mathbf{Z}'\mathbf{Z}) = \bar{y}_{1}$ as a test statistic, and an estimator
\item If $\mathbf{z} \equiv \mathbf{d}$, then $\bar{y}_{1}$ is
  unbiased for $\mu_{1}$, under both SRS and independent sampling.
}


\begin{frame}{The ACE ; unbiased estimation}
  
\end{frame}
\itnote{
\item For the moment, assume full compliance, so that $D \equiv Z$.
\item G\&G on why unbiasedness is good: p. 34.
\item A nice thing about this is that the difference of means is
  unbiased for the ACE whatever the (non-interfering) potential
  outcome schedule.
\item DISCUSS VARIANCE FORMULA HERE, OR IN SEPARATE SLIDE?
}

\begin{frame}{The Neyman justification for the 2-sample t-statistic} \pause
 \framesubtitle{I.e., estimating treatment effect as %
$\bar{y}_{1} - \bar{y}_0   \pm \sqrt{\mathrm{SE}(\bar{y}_{1})^{2} +
  \mathrm{SE}(\bar{y}_{0}) ^{2}}$ ($\mathrm{SE}(\bar{y}_{j})^{2} = \sigma_{j}^{2}/n_{j} $) }
\pause

\begin{columns}
  \begin{Column}
    {\usebeamercolor[fg]{titlelike} Canonical approach}  
    \begin{itemize}[<+->]
    \item $(Y_{0i}: i=1, \ldots, n_{0})  $, $(Y_{1i}: i=1, \ldots, n_{1})  $ are
i.i.d., mutually indep., with 2 finite moments. 
    \item $\mathbf{E}(\bar{Y}_{1} - \bar{Y}_{0}) =
      \mathbf{E}(\bar{Y}_{1}) - \mathbf{E}(\bar{Y}_{0}) = \mu_{1} - \mu_{0}$
    \item $\mathrm{Var}(\bar{Y}_{1} - \bar{Y}_{0}) =
      \mathrm{Var}(\bar{Y}_{1}) + \mathrm{Var}(\bar{Y}_{0}) =
      \sigma_{1}/n_{1} + \sigma_{0}/n_{0}$
    \item Finally, $\mathbf{E}(\frac{1}{n_{j}-1} \sum_{1}^{n_{j}}
      (Y_{ji} - \bar{Y}_{j} )^{2}) = \sigma^{2}_{i}$.
    \end{itemize}
 \end{Column}
  \begin{Column}
    {\usebeamercolor[fg]{titlelike} Neyman's approach}  
    \begin{itemize}[<+->]
    \item Single population of size $N$. Potential outcomes, w/ no
  interference.  T and C groups are simple
   disjoint random samples, sizes $n_{0}$, $n_{1}$.
 \item $\mathbf{E}(n_{1}^{-1}\mathbf{Z}'\mathbf{y}_{t} - n_{0}^{-1}(\mathbf{1}-
   \mathbf{Z})'\mathbf{y}_{c} ) = \cdots = N^{-1}\sum_{1}^{N} y_{ti} -
   N^{-1}\sum_{1}^{N} y_{ci}$
   \item $\mathrm{Var}(n_{1}^{-1}\mathbf{Z}'\mathbf{y}_{t} - n_{0}^{-1}(\mathbf{1}-
   \mathbf{Z})'\mathbf{y}_{c} ) = \cdots \leq \frac{N}{N-1}
   \left(\frac{\sigma_{1}^{2}}{n_{1}}  +
     \frac{\sigma_{0}^{2}}{n_{0}}\right)$     
\item Finally, $\mathbf{E}(\frac{1}{\# \mathbf{s}} \sum_{i \in \mathbf{s}}
      (y_{i} - \bar{y}_{\mathbf{s}} )^{2}) = \frac{N}{N-1}\sigma^{2}$.

    \end{itemize}
 \end{Column}
\end{columns}
\pause
Either way, unbiasedness limits error of estimation, error of error of estimation. 
\end{frame}

\itnote{
\item (go over this)
\item Discuss unbiasedness, both ways.
\item Put up Finucan
}

\begin{frame}{A Neyman-compatible justification for the paired t-statistic}
 \framesubtitle{i.e., $\widehat{\mathrm{ACE}} = \bar{d} \pm s_{d}/\sqrt{n}$} 

\end{frame}

\itnote{
\item If $d$'s aren't too crazy then $\hat{\mu}$ is consistent, in triangular array sense
\item Estimating equation formulation
\item The form of the ``robust standard error''
\item Easy to add in weights
\item See also Imai et al 2009 Prop 1 ff
\item (ran out of time for tex-ing)
}
\section{Common estimation targets in comparative studies}


\begin{frame}{ATEs and ACEs; SATEs and PATEs}

  \begin{itemize}
  \item ATE = Average treatment effect; ACE = Average causal effect

  \item SATE = \textit{sample} average treatment effect
  \item Ordinarily, refer to the same thing: the effect of \textit{assignment} to treatment in the study population.
  \item PATE = \textit{population} average treatment effect
  \item Limitations of the PATE:
    \begin{itemize}
    \item estimability
    \item ambiguity
    \end{itemize}

  \end{itemize}

\end{frame}


% \begin{frame}{Conditional expectation}
  
%   \begin{itemize}
%   \item $\mathrm{P}(A|B) =  $ conditional probability of A given that B
%   \item $\mathrm{E}(V|B) = \sum_v v\mathrm{P} ((V=v|B)$
%   \item if RVs $W$ and $V$ are independent, then $\mathrm{E}(V|W=w) = \mathrm{E}(V)$.
%   \item Random assignment ensures that $Z$ is independent of $Y_0$, $Y_1$.
%   \item So under random assignment, $\mathrm{E}(Y_0|Z=0) = \mathrm{E}(Y_0)$;  $\mathrm{E}(Y_1|Z=1) = \mathrm{E}(Y_1)$.
%   \item Note that $Z$ is not generally independent of $Y=DY_1 + (1-D)Y_0$!
%   \end{itemize}
% \end{frame}
% \note{
% ``ETT''=$\EE\{\mathrm{ACE}(\mathbf{X})| Z=1\} $}

\begin{frame}{FACEs and ACEs (Holland, 1988, \textit{Soc Meth}) }
  \begin{enumerate}[<+->]
  \item   Compare $\EE(Y | Z=1, \mathbf{x})$ to $\EE(Y_{t}| \mathbf{x})$.  In
  an experiment, the same thing -- but how about in an obs study?
\item Likewise  $\EE(Y | Z=0, \mathbf{x})$ vs $\EE(Y_{c}| \mathbf{x})$.
\item ``ACE'' = $\EE(Y_t - Y_c| \mathbf{x}) = \EE(Y_{t}| \mathbf{x}) - \EE(Y_{c}| \mathbf{x})$
\item ``FACE'' = $\EE(Y | Z=1, \mathbf{x}) - \EE(Y | Z=0, \mathbf{x})$
\item In the absence of selection bias, the two coincide:
$$ (Y_{t}, Y_{c}) \perp Z | \mathbf{X}$$
Not ordinarily otherwise.
  \end{enumerate}

Jargon:
``ACE'' above sometimes called ``$\mathrm{ACE}(\mathbf{x})$'',
  in which case $\mathrm{ACE} = \EE\mathtt{ACE}(\mathtt{X}) = \EE\{ \EE(Y_{t}|\mathbf{X}) -
  \EE(Y_{c}|\mathbf{X}) \}$.


\end{frame}

\itnote{
\item W16: SKIP ME
\item Refer to sec 2.6 of G\&G 
}
\begin{frame}{Per-protocol and intention to treat}

When there is \textit{non-compliance}, $Z$ and $D$ may differ.  \pause  

  \begin{columns}
    \begin{Column}
  {\usebeamercolor[fg]{titlelike} The per-protocol estimator} \\      
$\frac{1}{\# \{i: D_i = 1\}} \sum_{i:D_i=1} Y_i - \frac{1}{\# \{j: D_j = 0\}} \sum_{j:D_j=0} Y_j$
\bigskip

\uncover<3->{Estimates a FACE-like quantity}
\vspace{.5\textheight} 
\mbox{ }

    \end{Column}
    \begin{Column}
  {\usebeamercolor[fg]{titlelike} The intention-to-treat estimator} \\      
$\frac{1}{\# \{i: Z_i = 1\}} \sum_{i:Z_i=1} Y_i - \frac{1}{\# \{j: Z_j = 0\}} \sum_{j:Z_j=0} Y_j$
\bigskip

\uncover<2->{Estimates the intention to treat effect (the ATE)}

\vspace{.5\textheight} 
\mbox{ }
    \end{Column}

  \end{columns}
\end{frame}

\begin{frame}{The complier average causal effect via Bloom's(1984) method}
  \begin{itemize}
  \item intention-to-treat effect (Little \& Yau's [1998] $\delta$) vs
    complier average causal effect ($\delta_{c}$).
  \item $\delta = \pi_{c} \delta_{c} + \pi_{n} \delta_{n} $
  \item Assumptions: SUTVA, exclusion, monotonicity.
 \end{itemize}

\igrphx{SalkVtable-full}
\end{frame}

\begin{frame}{Biased and unbiased ATE estimation in experiments}
  
\end{frame}
\note{Having assigned Aronow and Middleton 2015 for reading, I
  discussed a little bit how clusterintg means the subject level
  difference in differences can be biased.}

\begin{frame}{Attributable effects}
  
When $y$ is binary (and sometimes otherwise), $\mathbf{z}'\mathbf{y} - \mathbf{z}'\mathbf{y}_{c}$ is known as the \textit{attributable effect} (Rosenbaum, 2001, \textit{Biometrika}).
\begin{itemize}
\item Motivation: How does the number of successes that were observed
  compare to the number of successes that would have been observed had
  no one received treatment?
\item An estimation target\ldots
\item despite being the value of a random variable
\item Rosenbaum (2001, 2002; \textit{DOS}) offers methods for testing hypotheses about the value of $\mathbf{z}'\mathbf{y} - \mathbf{z}'\mathbf{y}_{c}$.
\item<2-> For estimation, suffices to estimate $\mathbf{z}'\mathbf{y}_{c}$. (Why?)
\item<2-> If everyone w/ $z=0$ received control, then you can estimate  $\mathbf{z}'\mathbf{y}_{c}$ by estimating  $\mathbf{1}'\mathbf{y}_{c}$, the total of $y_{c}$s.
\item<2-> To do that, can employ estimation techniques from survey sampling (Hansen \& Bowers, 2009, \textit{J Amer Statist Assoc}; Aronow \& Middleton, 2013, \textit{J. Causal Inference}).
\end{itemize}


\end{frame}

\begin{frame}{SE's for AEs}
  
\end{frame}
\itnote{
\item Conceptual issue: when you're estimating the value of an RV,
  should your SE encapsulate the sampling variability that RV, or just
  the variability of the error of your estimate?  Hansen \& Bowers
  2009 opt for the latter. 
\item Hansen \& Bowers's SE vs the Neyman SE
  \begin{enumerate}
  \item 2 terms rather than 1
  \item Contrib from fpc
  \end{enumerate}
\item What the ? was the Abadie reference on this?
}

\begin{frame}{Votes-per-contact versus CACE}
  
\end{frame}
\itnote{
\item Two ratio-type estimators, one estimating a parameter, one an RV
\item (See last couple of exercises)
\item (There's an open problem lurking here)
}
\end{document}


\section{Differences-in-differences}

\begin{frame}{D-in-D for studies with a lagged measure of the outcome}

The \texttt{acorn} data set has

  

\end{frame}

