---
title: Non-bipartite Matching
date: '`r format(Sys.Date(), "%B %d, %Y")`'
author: ICPSR 2017 Session 2
bibliography:
 - refs.bib
 - BIB/master.bib
 - BIB/misc.bib
fontsize: 10pt
geometry: margin=1in
graphics: yes
biblio-style: authoryear-comp
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: true
    latex_engine: xelatex
    citation_package: biblatex
    template: icpsr.beamer
    includes:
        in_header:
           - defs-all.sty
---


<!-- Make this document using library(rmarkdown); render("day12.Rmd") -->


```{r include=FALSE, cache=FALSE}
# Some customization.  You can alter or delete as desired (if you know what you are doing).
# knitr settings to control how R chunks work.
rm(list=ls())

require(knitr)

## This plus size="\\scriptsize" from https://stackoverflow.com/questions/26372138/beamer-presentation-rstudio-change-font-size-for-chunk

knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before)
    return(options$size)
})

knit_hooks$set(plotdefault = function(before, options, envir) {
    if (before) par(mar = c(3, 3, .1, .1),oma=rep(0,4),mgp=c(1.5,.5,0))
})

opts_chunk$set(
  tidy=FALSE,     # display code as typed
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='\\scriptsize',
  out.width='.8\\textwidth',
  fig.retina=FALSE,
  message=FALSE,
  comment=NA,
  mysize=TRUE,
  plotdefault=TRUE)

if(!file.exists('figs')) dir.create('figs')

options(digits=4,
	scipen=8,
	width=132
	)
```

```{r eval=FALSE, include=FALSE, echo=FALSE}
## Run this only once and then not again until we want a new version from github
library('devtools')
library('withr')
with_libpaths('./lib', install_github("markmfredrickson/RItools"), 'pre')

## Having downloaded optmatch from Box OR http://jakebowers.org/ICPSR for mac (tgz) or windows (zip)
## For Mac
## with_libpaths('./lib',install.packages('optmatch_0.9-8.9003.tgz', repos=NULL),'pre')
## For Windows
## with_libpaths('./lib',install.packages('optmatch_0.9-8.9003.zip', repos=NULL),'pre')

## Or if you have all of the required libraries (like fortran and c++) for compilation use
with_libpaths('./lib', install_github("markmfredrickson/optmatch"), 'pre')
```

```{r echo=FALSE}
library(dplyr)
library(RItools,lib.loc="./lib")
library(optmatch,lib.loc="./lib")
library(nbpMatching)
library(lmtest)
library(sandwich)
```

## Today

\begin{enumerate}
\item Agenda: Non-bipartite matching.
\item Reading for this week: (1) Non-bipartite matching DOS Chap 11 and \autocite{lu2011optimal}  and DOS 12 (longitudinal applications of non-bipartite matching) and (2) Sensitivity analysis DOS Chap 3 \autocite{hhh2010}
\item Questions arising from the reading or assignments or life?
\item Recap: How to make a matched design that warrants causal interpretations of comparisons (decisions and strategies that are part of research design; matching on missingness and `fill.NAs`; `exactMatch`; `caliper`; `min.controls`; `effectiveSampleSize`); Modes of statistical inference for causal quantities (and the argument for the design-based / as-if-randomized approach after matching; the `optmatch` matching creates a design like a block-randomized study so analyze it as if it were a block-randomized study. ).
\end{enumerate}


## How do perceptions of place influence attitudes?

\autocite{wong2012jop} set out to measure perceptions of environments using an
internet survey of Canadians during 2012 which each respondent drew a free hand
map of their "local community" and then reported their understanding of the
demographic breakdown of this place.

```{r results='hide'}
## White English Speaking Canadians only
load(url("http://jakebowers.org/ICPSR/canadamapdat.rda"))
summary(canadamapdat)
```

## Capturing perceptions

\centering
\igrphx{images/TwoMapsToronto.png}


## Capturing perceptions

\centering
\igrphx{images/TorontoAllCommunities1.png}

## Capturing perceptions

\centering
\igrphx{images/TMLCCPerceptionsQuestion.pdf}

## Capturing perceptions

```{r echo=FALSE}
par(mfrow=c(1,2))
with(canadamapdat,scatter.smooth(vm.da,vm.community.norm2,xlim=c(0,1),ylim=c(0,1),lpars=list(lwd=2),main="DA"))
with(canadamapdat,scatter.smooth(vm.csd,vm.community.norm2,xlim=c(0,1),ylim=c(0,1),lpars=list(lwd=2),main="CSD"))
##summary(canadamapdat$vm.community.norm2)
```




## Codebook: Mainly for Rmd file

\scriptsize
The variables are: age in years, income as a scale, sex in categories, a
social.capital scale coded to run 0 to 1, country of ancestry in categories,
csd.pop is population of the Census Subdivision (like a municipality), vm.csd
is 2006 proportion visible minority in the CSD, vm.da is proportion visible
minority in the Census Dissemination Area (a small area containing 400--700
persons), and vm.community.norm2 is the proportion of visible minorities
reported by respondents in their map of their local community,
community_area_km is the area within their drawing in square km.

## How to make the case for perceptions?

If we could randomly assign different perceptions to people, we could claim
that differences of perceptions matter (above and beyond and independent of
objective characteristics of the context).

\medskip

What is an observational design that would do this? Match people on objective
context (and maybe covariates) who differ in perceptions.

\medskip

But perceptions are continuous not binary: rather than matching $m$ "treated"
to $n-m$ "controls", we want to compare all $n$ with all $n$ respondents.

```{r echo=FALSE}
## Exclude people who did not offer a perception or an outcome
wrkdat<-canadamapdat[!is.na(canadamapdat$vm.community.norm2) &
		     !is.na(canadamapdat$social.capital01),]
```

## Create $n \times n$ distance matrices

Our main design here matches people with similar neighborhood proportions of visible minorities.

```{r }
scalar.dist<-function(v){
  ## Utility function to make n x n abs dist matrices
  outer(v,v,FUN=function(x,y){ abs(x-y) })
}

vmdaDist<-scalar.dist(wrkdat$vm.da) 
dimnames(vmdaDist)<-list(row.names(wrkdat), row.names(wrkdat))
## The nbpmatching way (Mahalanobis \equiv standardized in one dimension) takes a while:
##obj.com.dist.mat2<-distancematrix(gendistance(wrkdat[,"vm.da",drop=FALSE]))
## compare to tmp<-scalar.dist(wrkdat$vm.da/sd(wrkdat$vm.da))
wrkdat$vm.da[1:4]
diff(wrkdat$vm.da[1:4])
vmdaDist[1:4,1:4]
```

## Non-bipartite match

```{r cache=TRUE}
vmdaDistMat <- distancematrix(vmdaDist)
nbp1match<-nonbimatch(vmdaDistMat)
nbp1<-get.sets(nbp1match$matches,remove.unpaired=TRUE)
wrkdat[names(nbp1),"nbp1"]<-nbp1
nbp1[1:5]
table(is.na(wrkdat$nbp1)) ## recall the "ghost message"
```

## Inspect the solution

```{r results="hide"}
table(wrkdat$nbp1)
nbp1vmdiffs<-tapply(wrkdat$vm.da,wrkdat$nbp1,function(x){ abs(diff(x)) })
summary(nbp1vmdiffs)
```


## Inspect the solution

```{r results='hide',eval=FALSE}
source(url("http://jakebowers.org/Matching/nonbimatchingfunctions.R"))
nbmplot(wrkdat,yvar="vm.da",xvar="vm.community.norm2",strata="nbp1",points=FALSE)
```

## Assess balance

Now we cannot ask whether the treatment and control groups look appropriately similar, but we can still compare the **relationships** between the adjusted variable (`vm.da`) and other covariates.

```{r results="hide"}
thecovs<-c("age","income.coded","education","x.years","sex",
           "csd.pop","vm.csd","community_area_km")
balfmla<-reformulate(thecovs,response="vm.da")
xb1<-xBalance(balfmla,strata=list(unstrat=NULL,nbp1=~nbp1), report="all",data=wrkdat) 
xb1$overall
xb1$results[,,"nbp1"]
```

## Improve balance using penalties and dropping observations

  For example, we might want to require matches within Province, to give
  special attention to csd.pop (so that we are not comparing people in small
  towns to people in large towns), and community_area_km (so that we are not
  comparing people who drew big maps to people who drew small maps). And we
  might also want to drop the 8 least well matched observations. (Choosing 8
  here arbitrarily.)


```{r results="hide"}
rescale01<-function(x){
  (x-min(x,na.rm=TRUE))/(max(x,na.rm=TRUE)-min(x,na.rm=TRUE))
}

csdpopDist<-scalar.dist(wrkdat$csd.pop)
dimnames(csdpopDist)<-list(row.names(wrkdat),row.names(wrkdat))

## Since we have some missing values on community area, and we would like to
## match people who are both missing, we will give it a very large value.
wrkdat$commarea<-ifelse(is.na(wrkdat$community_area_km),
			max(wrkdat$community_area_km,na.rm=TRUE)*10,
			wrkdat$community_area_km)

areaDist<-scalar.dist(log(wrkdat$commarea))
dimnames(areaDist)<-list(row.names(wrkdat),row.names(wrkdat))

csdpopDist01<-rescale01(csdpopDist)
areaDist01<-rescale01(areaDist)

summary(as.vector(csdpopDist01))
summary(as.vector(areaDist01))
summary(as.vector(vmdaDist))

maxvmdaDist<-max(as.vector(vmdaDist))

vmdaPen1<-vmdaDist+(maxvmdaDist*csdpopDist01)+(maxvmdaDist*areaDist01)

## Here you can see how the penalties change the distance matrix
vmdaDist[1:5,1:5]
csdpopDist01[1:5,1:5]
areaDist01[1:5,1:5]

vmdaPen1[1:5,1:5]

## now decide how many to drop
vmdaPhPen<-make.phantoms(vmdaPen1,8,maxval = max(as.vector(vmdaPen1))*10)
```

```{r cache=TRUE}
vmdaPhPenMat <- distancematrix(vmdaPhPen)

nbp2match<-nonbimatch(vmdaPhPenMat)

nbp2<-get.sets(nbp2match$matches,remove.unpaired=TRUE)
wrkdat[names(nbp2),"nbp2"]<-nbp2
```

## Assess this new match

Is this match better or worse (in terms of balance? in terms of within-set distances?)

```{r echo=FALSE,results="hide"}
xb2<-xBalance(balfmla,strata=list(unstrat=NULL,nbp1=~nbp1,nbp2=~nbp2),
	      report="all",data=wrkdat)
xb2$overall[2:3,]
xb2$results[,"p",c("nbp1","nbp2")]
```

```{r eval=FALSE}
nbmplot(wrkdat,yvar="vm.da",xvar="vm.community.norm2",strata="nbp2",points=FALSE)
```

## Now assess hypotheses about effects

Now, test the hypothesis of no relationship between perceptions
`vm.community.norm2` and `social capital`.

```{r eval=FALSE,echo=FALSE,results="hide"}
## These are the same test in this case
library(coin)
test1<-independence_test(social.capital01~vm.community.norm2|nbp1,data=wrkdat[!is.na(wrkdat$nbp1),])

test2<-xBalance(vm.community.norm2~social.capital01,
		strata=list(nbp1=~nbp1),
		data=wrkdat,
		report=c("adj.mean.diffs","chisquare.test","z.scores","p.values"))
```

## Describe the differences within pairs

One idea is to ask whether the person who is higher in perceptions tends to be higher (or lower) in social.capital. What do you think the following analysis shows?

```{r }
rank.pairs<-function (x, block) { ## Identify the low and high subj in each pair
  unsplit(lapply(split(x, block), function(x) {
    rank(x)
  }), block)
}

wrkdat$scRank<-with(wrkdat,rank.pairs(social.capital01,nbp1))
wrkdat$vmCRank<-with(wrkdat,rank.pairs(vm.community.norm2,nbp1))

with(wrkdat,tapply(scRank,vmCRank,mean))
with(wrkdat,tapply(scRank,vmCRank,length))
```

## Summarize mean differences within pairs

We have more information available than merely ranking pair members. If perceptions matters for social capital then we would expect pairs differing greatly in subjective context to display greater differences in social capital than pairs that differ a little. A linear model is a nice tool to use in summarizing this kind of relationship.

Please interpret the following results:

```{r results="hide"}
align.by.block<-function (x, block, fn = mean, thenames=NULL) { ## By default, this rescales each observation to be the distance from the group mean.
  newx<-unsplit(lapply(split(x, block), function(x) {
    x - fn(x)
  }), block)
  if(!is.null(names)){ names(newx)<-thenames }
  return(newx)
}

wrkdat$scMD<-with(wrkdat,align.by.block(social.capital01,nbp1))
wrkdat$vmcn2MD<-with(wrkdat,align.by.block(vm.community.norm2,nbp1))

wrkdat[order(wrkdat$nbp1),c("social.capital01","scMD","vm.community.norm2","vmcn2MD","nbp1")][1:10,]

## notice that aligning or pair-mean-centering the data preserves the within
## set relationships
summary(tapply(wrkdat$scMD,wrkdat$nbp1,function(x){ abs(diff(x)) }))
summary(tapply(wrkdat$social.capital01,wrkdat$nbp1,function(x){ abs(diff(x)) }))

lm1<-lm(scMD~vmcn2MD,data=wrkdat[!is.na(wrkdat$nbp1),])

library(sandwich)
library(lmtest)

source(url("http://jakebowers.org/ICPSR/confintHC.R"))

theHC2ci<-confint.HC(lm1,level=.95,parm="vmcn2MD",thevcov=vcovHC(lm1,type="HC2"))

c(ATE=coef(lm1)[[2]],ci=theHC2ci)
```

```{r eval=FALSE}
with(wrkdat,scatter.smooth(vmcn2MD,scMD,span=.3,cex=.7,col="gray",pch=19,lpars=list(lwd=2)))
abline(h=0,lwd=.5)
```

\note{
Within matched pair, the person who perceives more visible minorities within set tends to report
lower social capital than the person who perceives fewer visible minorities
within set.

The largest difference is about .4 (or 40 percentage points!), the model
predicts that social capital would differ by about `coef(lm1)[[2]]*.4` for such a difference. This is about
`coef(lm1)[[2]]*.4/sd(wrkdat$scMD,na.rm=TRUE)` of a standard deviation
of the social capital scale. Or about
`coef(lm1)[[2]]*.4/abs(diff(range(wrkdat$scMD,na.rm=TRUE)))` of the range.
}

## Another estimation approach

\autocite{smith:1997} presents a multi-level modelling approach to taking
matched sets into account. The weights implied here are a bit different from
the weights that we've discussed before (although with pairs they might be more
or less the same). What is the data model? What additional assumptions are involved
here?

```{r cache=TRUE,results="hide", warning=FALSE}
library(lme4)

wrkdat$vmCbi<-ave(wrkdat$vm.community.norm2,wrkdat$nbp1)
lmer1<-lmer(social.capital01~vm.community.norm2+vmCbi+(1|nbp1),data=wrkdat)

confint(lmer1)

## Notice
table(table(wrkdat$dauid))

## So maybe:

lmer2<-lmer(social.capital01~vm.community.norm2+vmCbi+(1|nbp1)+(1|dauid),data=wrkdat)

confint(lmer2)
```

## Anything Else?

## References
